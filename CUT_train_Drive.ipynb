{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CUT-train-Drive.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dariianina/ThermoGen/blob/main/CUT_train_Drive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVR4bEt9Ptel"
      },
      "source": [
        "#CUT\n",
        "This new model uses contrastive learning (the hot technique of the moment) to better train unaligned image to image translation (i.e. CycleGAN)\n",
        "\n",
        "[GitHub](https://github.com/taesungp/contrastive-unpaired-translation) | [Website](http://taesung.me/ContrastiveUnpairedTranslation/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xzc2aQYcXo7-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1453328a-6eb3-4450-d7e8-5cc36230d28e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwtxgK2rYAiN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87358e29-02f3-4cc7-fc34-921c717c41b4"
      },
      "source": [
        "import os\n",
        "if os.path.isdir(\"/content/drive/My Drive/colab-cut-test/CUT\"):\n",
        "    %cd /content/drive/My\\ Drive/colab-cut-test/CUT\n",
        "else:\n",
        "    %cd /content/drive/My\\ Drive\n",
        "    #!mkdir colab-cut-test\n",
        "    %cd ./colab-cut-test/\n",
        "    #!git clone https://github.com/taesungp/contrastive-unpaired-translation CUT\n",
        "    %cd CUT\n",
        "\n",
        "#dependencies\n",
        "#!pip install dominate visdom GPUtil"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/colab-cut-test/CUT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1tdZoGaMOGf"
      },
      "source": [
        "## Download pre-built datasets\n",
        "\n",
        "**For custom datasets:** create a folder in `./datasets` and put two folders inside it. `trainA` should contain images from one domain and `trainB` should contain images from another domain."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRI0XL6xK386"
      },
      "source": [
        "#datasets available: apple2orange, summer2winter_yosemite, horse2zebra, monet2photo, cezanne2photo, ukiyoe2photo, vangogh2photo, maps, cityscapes, facades, iphone2dslr_flower, ae_photos, grumpifycat\n",
        "dataset = \"horse2zebra\"\n",
        "#example: download the russian blue cats to grumpy cats dataset\n",
        "!bash ./datasets/download_cut_dataset.sh $dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = \"rgb2therm\"\n",
        "#!git clone https://github.com/vision-cidis/CIDIS-dataset.git"
      ],
      "metadata": {
        "id": "lXWQbFt689li"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r ./CIDIS-dataset/dataset/visible/train ./datasets/rgb2therm/trainA\n",
        "!cp -r ./CIDIS-dataset/dataset/visible/test ./datasets/rgb2therm/testA\n",
        "!cp -r ./CIDIS-dataset/dataset/thermal/train ./datasets/rgb2therm/trainB\n",
        "!cp -r ./CIDIS-dataset/dataset/thermal/test ./datasets/rgb2therm/testB"
      ],
      "metadata": {
        "id": "3hET0Wjq9p21"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RGB to greyscale"
      ],
      "metadata": {
        "id": "phAYiRxbfXfb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B6Zeq3UMf63Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IriT_YgSdQ-z"
      },
      "source": [
        "## Train\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oycbT_1odWFf"
      },
      "source": [
        "dataset_path = './datasets/' + dataset\n",
        "project_name = dataset + '_CUT'\n",
        "load_size = 286\n",
        "crop_size = 256"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aa_XrrrmddF7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ded73429-6c6c-4119-93d6-15429792c0c2"
      },
      "source": [
        "!python train.py --max_dataset_size 4 \\\n",
        "--lr 0.002 \\\n",
        "--input_nc 1 \\\n",
        "--output_nc 1 \\\n",
        "--dataroot $dataset_path \\\n",
        "--name $project_name \\\n",
        "--CUT_mode CUT \\\n",
        "--load_size $load_size \\\n",
        "--crop_size $crop_size \\\n",
        "--display_id 0\n",
        "# --continue_train False \\"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------- Options ---------------\n",
            "                 CUT_mode: CUT                           \n",
            "               batch_size: 1                             \n",
            "                    beta1: 0.5                           \n",
            "                    beta2: 0.999                         \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "           continue_train: False                         \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ./datasets/rgb2therm          \t[default: placeholder]\n",
            "             dataset_mode: unaligned                     \n",
            "                direction: AtoB                          \n",
            "              display_env: main                          \n",
            "             display_freq: 400                           \n",
            "               display_id: 0                             \t[default: None]\n",
            "            display_ncols: 4                             \n",
            "             display_port: 8097                          \n",
            "           display_server: http://localhost              \n",
            "          display_winsize: 256                           \n",
            "               easy_label: experiment_name               \n",
            "                    epoch: latest                        \n",
            "              epoch_count: 1                             \n",
            "          evaluation_freq: 5000                          \n",
            "        flip_equivariance: False                         \n",
            "                 gan_mode: lsgan                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: xavier                        \n",
            "                 input_nc: 1                             \t[default: 3]\n",
            "                  isTrain: True                          \t[default: None]\n",
            "               lambda_GAN: 1.0                           \n",
            "               lambda_NCE: 1.0                           \n",
            "                load_size: 286                           \n",
            "                       lr: 0.002                         \t[default: 0.0002]\n",
            "           lr_decay_iters: 50                            \n",
            "                lr_policy: linear                        \n",
            "         max_dataset_size: 4                             \t[default: inf]\n",
            "                    model: cut                           \n",
            "                 n_epochs: 200                           \n",
            "           n_epochs_decay: 200                           \n",
            "               n_layers_D: 3                             \n",
            "                     name: rgb2therm_CUT                 \t[default: experiment_name]\n",
            "                    nce_T: 0.07                          \n",
            "                  nce_idt: True                          \n",
            "nce_includes_all_negatives_from_minibatch: False                         \n",
            "               nce_layers: 0,4,8,12,16                   \n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netF: mlp_sample                    \n",
            "                  netF_nc: 256                           \n",
            "                     netG: resnet_9blocks                \n",
            "                      ngf: 64                            \n",
            "             no_antialias: False                         \n",
            "          no_antialias_up: False                         \n",
            "               no_dropout: True                          \n",
            "                  no_flip: False                         \n",
            "                  no_html: False                         \n",
            "                    normD: instance                      \n",
            "                    normG: instance                      \n",
            "              num_patches: 256                           \n",
            "              num_threads: 4                             \n",
            "                output_nc: 1                             \t[default: 3]\n",
            "                    phase: train                         \n",
            "                pool_size: 0                             \n",
            "               preprocess: resize_and_crop               \n",
            "          pretrained_name: None                          \n",
            "               print_freq: 100                           \n",
            "         random_scale_max: 3.0                           \n",
            "             save_by_iter: False                         \n",
            "          save_epoch_freq: 5                             \n",
            "         save_latest_freq: 5000                          \n",
            "           serial_batches: False                         \n",
            "stylegan2_G_num_downsampling: 1                             \n",
            "                   suffix:                               \n",
            "         update_html_freq: 1000                          \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [UnalignedDataset] was created\n",
            "model [CUTModel] was created\n",
            "The number of training images = 4\n",
            "create web directory ./checkpoints/rgb2therm_CUT/web...\n",
            "/content/drive/MyDrive/colab-cut-test/CUT/models/networks.py:569: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  patch_id = torch.tensor(patch_id, dtype=torch.long, device=feat.device)\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 11.366 M\n",
            "[Network F] Total number of parameters : 0.560 M\n",
            "[Network D] Total number of parameters : 2.763 M\n",
            "-----------------------------------------------\n",
            "End of epoch 1 / 400 \t Time Taken: 10 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 2 / 400 \t Time Taken: 1 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 3 / 400 \t Time Taken: 1 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 4 / 400 \t Time Taken: 1 sec\n",
            "learning rate = 0.0020000\n",
            "saving the model at the end of epoch 5, iters 20\n",
            "End of epoch 5 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 6 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 7 / 400 \t Time Taken: 1 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 8 / 400 \t Time Taken: 1 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 9 / 400 \t Time Taken: 1 sec\n",
            "learning rate = 0.0020000\n",
            "saving the model at the end of epoch 10, iters 40\n",
            "End of epoch 10 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 11 / 400 \t Time Taken: 1 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 12 / 400 \t Time Taken: 3 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 13 / 400 \t Time Taken: 1 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 14 / 400 \t Time Taken: 1 sec\n",
            "learning rate = 0.0020000\n",
            "saving the model at the end of epoch 15, iters 60\n",
            "End of epoch 15 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 16 / 400 \t Time Taken: 1 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 17 / 400 \t Time Taken: 1 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 18 / 400 \t Time Taken: 1 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 19 / 400 \t Time Taken: 1 sec\n",
            "learning rate = 0.0020000\n",
            "saving the model at the end of epoch 20, iters 80\n",
            "End of epoch 20 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 21 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 22 / 400 \t Time Taken: 1 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 23 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 24 / 400 \t Time Taken: 4 sec\n",
            "learning rate = 0.0020000\n",
            "(epoch: 25, iters: 4, time: 0.261, data: 0.079) G_GAN: 0.373 D_real: 0.219 D_fake: 0.171 G: 5.621 NCE_A: 4.696 NCE_B: 6.280 NCE_Y: 4.767 \n",
            "saving the model at the end of epoch 25, iters 100\n",
            "End of epoch 25 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 26 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 27 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 28 / 400 \t Time Taken: 1 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 29 / 400 \t Time Taken: 1 sec\n",
            "learning rate = 0.0020000\n",
            "saving the model at the end of epoch 30, iters 120\n",
            "End of epoch 30 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 31 / 400 \t Time Taken: 1 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 32 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 33 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 34 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "saving the model at the end of epoch 35, iters 140\n",
            "End of epoch 35 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 36 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 37 / 400 \t Time Taken: 1 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 38 / 400 \t Time Taken: 1 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 39 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "saving the model at the end of epoch 40, iters 160\n",
            "End of epoch 40 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 41 / 400 \t Time Taken: 1 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 42 / 400 \t Time Taken: 1 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 43 / 400 \t Time Taken: 1 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 44 / 400 \t Time Taken: 1 sec\n",
            "learning rate = 0.0020000\n",
            "saving the model at the end of epoch 45, iters 180\n",
            "End of epoch 45 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 46 / 400 \t Time Taken: 1 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 47 / 400 \t Time Taken: 1 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 48 / 400 \t Time Taken: 1 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 49 / 400 \t Time Taken: 1 sec\n",
            "learning rate = 0.0020000\n",
            "(epoch: 50, iters: 4, time: 0.335, data: 0.145) G_GAN: 0.682 D_real: 0.148 D_fake: 0.035 G: 5.681 NCE_A: 4.370 NCE_B: 6.451 NCE_Y: 4.177 \n",
            "saving the model at the end of epoch 50, iters 200\n",
            "End of epoch 50 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 51 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 52 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 53 / 400 \t Time Taken: 1 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 54 / 400 \t Time Taken: 1 sec\n",
            "learning rate = 0.0020000\n",
            "saving the model at the end of epoch 55, iters 220\n",
            "End of epoch 55 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 56 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 57 / 400 \t Time Taken: 1 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 58 / 400 \t Time Taken: 1 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 59 / 400 \t Time Taken: 1 sec\n",
            "learning rate = 0.0020000\n",
            "saving the model at the end of epoch 60, iters 240\n",
            "End of epoch 60 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 61 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 62 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 63 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 64 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "saving the model at the end of epoch 65, iters 260\n",
            "End of epoch 65 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 66 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 67 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 68 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 69 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "saving the model at the end of epoch 70, iters 280\n",
            "End of epoch 70 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 71 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 72 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 73 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 74 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "(epoch: 75, iters: 4, time: 0.384, data: 0.156) G_GAN: 0.478 D_real: 0.129 D_fake: 0.231 G: 5.383 NCE_A: 4.211 NCE_B: 6.223 NCE_Y: 4.282 \n",
            "saving the model at the end of epoch 75, iters 300\n",
            "End of epoch 75 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 76 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 77 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 78 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 79 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "saving the model at the end of epoch 80, iters 320\n",
            "End of epoch 80 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 81 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 82 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 83 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 84 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "saving the model at the end of epoch 85, iters 340\n",
            "End of epoch 85 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 86 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 87 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 88 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 89 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "saving the model at the end of epoch 90, iters 360\n",
            "End of epoch 90 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 91 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 92 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 93 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 94 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "saving the model at the end of epoch 95, iters 380\n",
            "End of epoch 95 / 400 \t Time Taken: 3 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 96 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 97 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 98 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 99 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "(epoch: 100, iters: 4, time: 0.416, data: 0.383) G_GAN: 0.349 D_real: 0.124 D_fake: 0.331 G: 5.066 NCE_A: 3.989 NCE_B: 6.246 NCE_Y: 3.917 \n",
            "saving the model at the end of epoch 100, iters 400\n",
            "End of epoch 100 / 400 \t Time Taken: 3 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 101 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 102 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 103 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 104 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "saving the model at the end of epoch 105, iters 420\n",
            "End of epoch 105 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 106 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 107 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 108 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 109 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "saving the model at the end of epoch 110, iters 440\n",
            "End of epoch 110 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 111 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 112 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 113 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 114 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "saving the model at the end of epoch 115, iters 460\n",
            "End of epoch 115 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 116 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 117 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 118 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 119 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "saving the model at the end of epoch 120, iters 480\n",
            "End of epoch 120 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 121 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 122 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 123 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 124 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "(epoch: 125, iters: 4, time: 0.436, data: 0.144) G_GAN: 0.725 D_real: 0.341 D_fake: 0.042 G: 5.947 NCE_A: 4.710 NCE_B: 6.334 NCE_Y: 4.621 \n",
            "saving the model at the end of epoch 125, iters 500\n",
            "End of epoch 125 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 126 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 127 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 128 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 129 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "saving the model at the end of epoch 130, iters 520\n",
            "End of epoch 130 / 400 \t Time Taken: 3 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 131 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 132 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 133 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 134 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "saving the model at the end of epoch 135, iters 540\n",
            "End of epoch 135 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 136 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 137 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 138 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 139 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "saving the model at the end of epoch 140, iters 560\n",
            "End of epoch 140 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 141 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 142 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 143 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 144 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "saving the model at the end of epoch 145, iters 580\n",
            "End of epoch 145 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 146 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 147 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 148 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 149 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "(epoch: 150, iters: 4, time: 0.447, data: 0.147) G_GAN: 0.771 D_real: 0.086 D_fake: 0.064 G: 6.120 NCE_A: 4.287 NCE_B: 7.399 NCE_Y: 4.361 \n",
            "saving the model at the end of epoch 150, iters 600\n",
            "End of epoch 150 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 151 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 152 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 153 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 154 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "saving the model at the end of epoch 155, iters 620\n",
            "End of epoch 155 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 156 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 157 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 158 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 159 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "saving the model at the end of epoch 160, iters 640\n",
            "End of epoch 160 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 161 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 162 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 163 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 164 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "saving the model at the end of epoch 165, iters 660\n",
            "End of epoch 165 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 166 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 167 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 168 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 169 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "saving the model at the end of epoch 170, iters 680\n",
            "End of epoch 170 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 171 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 172 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 173 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 174 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "(epoch: 175, iters: 4, time: 0.454, data: 0.139) G_GAN: 0.403 D_real: 0.337 D_fake: 0.095 G: 4.888 NCE_A: 4.325 NCE_B: 5.913 NCE_Y: 3.218 \n",
            "saving the model at the end of epoch 175, iters 700\n",
            "End of epoch 175 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 176 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 177 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 178 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 179 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "saving the model at the end of epoch 180, iters 720\n",
            "End of epoch 180 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 181 / 400 \t Time Taken: 3 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 182 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 183 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 184 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "saving the model at the end of epoch 185, iters 740\n",
            "End of epoch 185 / 400 \t Time Taken: 3 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 186 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 187 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 188 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 189 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "saving the model at the end of epoch 190, iters 760\n",
            "End of epoch 190 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 191 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 192 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 193 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 194 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "saving the model at the end of epoch 195, iters 780\n",
            "End of epoch 195 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 196 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 197 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 198 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "End of epoch 199 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0020000\n",
            "(epoch: 200, iters: 4, time: 0.459, data: 0.154) G_GAN: 0.386 D_real: 0.167 D_fake: 0.236 G: 4.757 NCE_A: 4.205 NCE_B: 5.966 NCE_Y: 2.941 \n",
            "saving the model at the end of epoch 200, iters 800\n",
            "End of epoch 200 / 400 \t Time Taken: 3 sec\n",
            "learning rate = 0.0019900\n",
            "End of epoch 201 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0019801\n",
            "End of epoch 202 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0019701\n",
            "End of epoch 203 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0019602\n",
            "End of epoch 204 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0019502\n",
            "saving the model at the end of epoch 205, iters 820\n",
            "End of epoch 205 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0019403\n",
            "End of epoch 206 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0019303\n",
            "End of epoch 207 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0019204\n",
            "End of epoch 208 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0019104\n",
            "End of epoch 209 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0019005\n",
            "saving the model at the end of epoch 210, iters 840\n",
            "End of epoch 210 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0018905\n",
            "End of epoch 211 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0018806\n",
            "End of epoch 212 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0018706\n",
            "End of epoch 213 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0018607\n",
            "End of epoch 214 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0018507\n",
            "saving the model at the end of epoch 215, iters 860\n",
            "End of epoch 215 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0018408\n",
            "End of epoch 216 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0018308\n",
            "End of epoch 217 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0018209\n",
            "End of epoch 218 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0018109\n",
            "End of epoch 219 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0018010\n",
            "saving the model at the end of epoch 220, iters 880\n",
            "End of epoch 220 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0017910\n",
            "End of epoch 221 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0017811\n",
            "End of epoch 222 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0017711\n",
            "End of epoch 223 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0017612\n",
            "End of epoch 224 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0017512\n",
            "(epoch: 225, iters: 4, time: 0.461, data: 0.422) G_GAN: 0.268 D_real: 0.215 D_fake: 0.261 G: 4.049 NCE_A: 2.969 NCE_B: 5.774 NCE_Y: 2.601 \n",
            "saving the model at the end of epoch 225, iters 900\n",
            "End of epoch 225 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0017413\n",
            "End of epoch 226 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0017313\n",
            "End of epoch 227 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0017214\n",
            "End of epoch 228 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0017114\n",
            "End of epoch 229 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0017015\n",
            "saving the model at the end of epoch 230, iters 920\n",
            "End of epoch 230 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0016915\n",
            "End of epoch 231 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0016816\n",
            "End of epoch 232 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0016716\n",
            "End of epoch 233 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0016617\n",
            "End of epoch 234 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0016517\n",
            "saving the model at the end of epoch 235, iters 940\n",
            "End of epoch 235 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0016418\n",
            "End of epoch 236 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0016318\n",
            "End of epoch 237 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0016219\n",
            "End of epoch 238 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0016119\n",
            "End of epoch 239 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0016020\n",
            "saving the model at the end of epoch 240, iters 960\n",
            "End of epoch 240 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0015920\n",
            "End of epoch 241 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0015821\n",
            "End of epoch 242 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0015721\n",
            "End of epoch 243 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0015622\n",
            "End of epoch 244 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0015522\n",
            "saving the model at the end of epoch 245, iters 980\n",
            "End of epoch 245 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0015423\n",
            "End of epoch 246 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0015323\n",
            "End of epoch 247 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0015224\n",
            "End of epoch 248 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0015124\n",
            "End of epoch 249 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0015025\n",
            "(epoch: 250, iters: 4, time: 0.463, data: 0.141) G_GAN: 0.348 D_real: 0.368 D_fake: 0.269 G: 4.171 NCE_A: 3.049 NCE_B: 6.032 NCE_Y: 2.387 \n",
            "saving the model at the end of epoch 250, iters 1000\n",
            "End of epoch 250 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0014925\n",
            "End of epoch 251 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0014826\n",
            "End of epoch 252 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0014726\n",
            "End of epoch 253 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0014627\n",
            "End of epoch 254 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0014527\n",
            "saving the model at the end of epoch 255, iters 1020\n",
            "End of epoch 255 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0014428\n",
            "End of epoch 256 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0014328\n",
            "End of epoch 257 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0014229\n",
            "End of epoch 258 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0014129\n",
            "End of epoch 259 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0014030\n",
            "saving the model at the end of epoch 260, iters 1040\n",
            "End of epoch 260 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0013930\n",
            "End of epoch 261 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0013831\n",
            "End of epoch 262 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0013731\n",
            "End of epoch 263 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0013632\n",
            "End of epoch 264 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0013532\n",
            "saving the model at the end of epoch 265, iters 1060\n",
            "End of epoch 265 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0013433\n",
            "End of epoch 266 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0013333\n",
            "End of epoch 267 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0013234\n",
            "End of epoch 268 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0013134\n",
            "End of epoch 269 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0013035\n",
            "saving the model at the end of epoch 270, iters 1080\n",
            "End of epoch 270 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0012935\n",
            "End of epoch 271 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0012836\n",
            "End of epoch 272 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0012736\n",
            "End of epoch 273 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0012637\n",
            "End of epoch 274 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0012537\n",
            "(epoch: 275, iters: 4, time: 0.464, data: 0.143) G_GAN: 0.310 D_real: 0.212 D_fake: 0.252 G: 4.054 NCE_A: 3.123 NCE_B: 5.944 NCE_Y: 2.165 \n",
            "saving the model at the end of epoch 275, iters 1100\n",
            "End of epoch 275 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0012438\n",
            "End of epoch 276 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0012338\n",
            "End of epoch 277 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0012239\n",
            "End of epoch 278 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0012139\n",
            "End of epoch 279 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0012040\n",
            "saving the model at the end of epoch 280, iters 1120\n",
            "End of epoch 280 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0011940\n",
            "End of epoch 281 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0011841\n",
            "End of epoch 282 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0011741\n",
            "End of epoch 283 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0011642\n",
            "End of epoch 284 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0011542\n",
            "saving the model at the end of epoch 285, iters 1140\n",
            "End of epoch 285 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0011443\n",
            "End of epoch 286 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0011343\n",
            "End of epoch 287 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0011244\n",
            "End of epoch 288 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0011144\n",
            "End of epoch 289 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0011045\n",
            "saving the model at the end of epoch 290, iters 1160\n",
            "End of epoch 290 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0010945\n",
            "End of epoch 291 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0010846\n",
            "End of epoch 292 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0010746\n",
            "End of epoch 293 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0010647\n",
            "End of epoch 294 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0010547\n",
            "saving the model at the end of epoch 295, iters 1180\n",
            "End of epoch 295 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0010448\n",
            "End of epoch 296 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0010348\n",
            "End of epoch 297 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0010249\n",
            "End of epoch 298 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0010149\n",
            "End of epoch 299 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0010050\n",
            "(epoch: 300, iters: 4, time: 0.465, data: 0.140) G_GAN: 0.307 D_real: 0.238 D_fake: 0.222 G: 3.689 NCE_A: 2.402 NCE_B: 5.614 NCE_Y: 2.130 \n",
            "saving the model at the end of epoch 300, iters 1200\n",
            "End of epoch 300 / 400 \t Time Taken: 3 sec\n",
            "learning rate = 0.0009950\n",
            "End of epoch 301 / 400 \t Time Taken: 3 sec\n",
            "learning rate = 0.0009851\n",
            "End of epoch 302 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0009751\n",
            "End of epoch 303 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0009652\n",
            "End of epoch 304 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0009552\n",
            "saving the model at the end of epoch 305, iters 1220\n",
            "End of epoch 305 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0009453\n",
            "End of epoch 306 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0009353\n",
            "End of epoch 307 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0009254\n",
            "End of epoch 308 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0009154\n",
            "End of epoch 309 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0009055\n",
            "saving the model at the end of epoch 310, iters 1240\n",
            "End of epoch 310 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0008955\n",
            "End of epoch 311 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0008856\n",
            "End of epoch 312 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0008756\n",
            "End of epoch 313 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0008657\n",
            "End of epoch 314 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0008557\n",
            "saving the model at the end of epoch 315, iters 1260\n",
            "End of epoch 315 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0008458\n",
            "End of epoch 316 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0008358\n",
            "End of epoch 317 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0008259\n",
            "End of epoch 318 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0008159\n",
            "End of epoch 319 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0008060\n",
            "saving the model at the end of epoch 320, iters 1280\n",
            "End of epoch 320 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0007960\n",
            "End of epoch 321 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0007861\n",
            "End of epoch 322 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0007761\n",
            "End of epoch 323 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0007662\n",
            "End of epoch 324 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0007562\n",
            "(epoch: 325, iters: 4, time: 0.466, data: 1.321) G_GAN: 0.355 D_real: 0.245 D_fake: 0.167 G: 3.881 NCE_A: 2.804 NCE_B: 5.733 NCE_Y: 2.042 \n",
            "saving the model at the end of epoch 325, iters 1300\n",
            "End of epoch 325 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0007463\n",
            "End of epoch 326 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0007363\n",
            "End of epoch 327 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0007264\n",
            "End of epoch 328 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0007164\n",
            "End of epoch 329 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0007065\n",
            "saving the model at the end of epoch 330, iters 1320\n",
            "End of epoch 330 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0006965\n",
            "End of epoch 331 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0006866\n",
            "End of epoch 332 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0006766\n",
            "End of epoch 333 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0006667\n",
            "End of epoch 334 / 400 \t Time Taken: 4 sec\n",
            "learning rate = 0.0006567\n",
            "saving the model at the end of epoch 335, iters 1340\n",
            "End of epoch 335 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0006468\n",
            "End of epoch 336 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0006368\n",
            "End of epoch 337 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0006269\n",
            "End of epoch 338 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0006169\n",
            "End of epoch 339 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0006070\n",
            "saving the model at the end of epoch 340, iters 1360\n",
            "End of epoch 340 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0005970\n",
            "End of epoch 341 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0005871\n",
            "End of epoch 342 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0005771\n",
            "End of epoch 343 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0005672\n",
            "End of epoch 344 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0005572\n",
            "saving the model at the end of epoch 345, iters 1380\n",
            "End of epoch 345 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0005473\n",
            "End of epoch 346 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0005373\n",
            "End of epoch 347 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0005274\n",
            "End of epoch 348 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0005174\n",
            "End of epoch 349 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0005075\n",
            "(epoch: 350, iters: 4, time: 0.466, data: 0.136) G_GAN: 0.341 D_real: 0.291 D_fake: 0.170 G: 3.692 NCE_A: 2.112 NCE_B: 5.842 NCE_Y: 2.099 \n",
            "saving the model at the end of epoch 350, iters 1400\n",
            "End of epoch 350 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0004975\n",
            "End of epoch 351 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0004876\n",
            "End of epoch 352 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0004776\n",
            "End of epoch 353 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0004677\n",
            "End of epoch 354 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0004577\n",
            "saving the model at the end of epoch 355, iters 1420\n",
            "End of epoch 355 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0004478\n",
            "End of epoch 356 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0004378\n",
            "End of epoch 357 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0004279\n",
            "End of epoch 358 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0004179\n",
            "End of epoch 359 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0004080\n",
            "saving the model at the end of epoch 360, iters 1440\n",
            "End of epoch 360 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0003980\n",
            "End of epoch 361 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0003881\n",
            "End of epoch 362 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0003781\n",
            "End of epoch 363 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0003682\n",
            "End of epoch 364 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0003582\n",
            "saving the model at the end of epoch 365, iters 1460\n",
            "End of epoch 365 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0003483\n",
            "End of epoch 366 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0003383\n",
            "End of epoch 367 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0003284\n",
            "End of epoch 368 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0003184\n",
            "End of epoch 369 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0003085\n",
            "saving the model at the end of epoch 370, iters 1480\n",
            "End of epoch 370 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002985\n",
            "End of epoch 371 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002886\n",
            "End of epoch 372 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002786\n",
            "End of epoch 373 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002687\n",
            "End of epoch 374 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002587\n",
            "(epoch: 375, iters: 4, time: 0.466, data: 0.140) G_GAN: 0.334 D_real: 0.273 D_fake: 0.177 G: 3.843 NCE_A: 2.953 NCE_B: 5.729 NCE_Y: 1.846 \n",
            "saving the model at the end of epoch 375, iters 1500\n",
            "End of epoch 375 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002488\n",
            "End of epoch 376 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002388\n",
            "End of epoch 377 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002289\n",
            "End of epoch 378 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002189\n",
            "End of epoch 379 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002090\n",
            "saving the model at the end of epoch 380, iters 1520\n",
            "End of epoch 380 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001990\n",
            "End of epoch 381 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001891\n",
            "End of epoch 382 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001791\n",
            "End of epoch 383 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001692\n",
            "End of epoch 384 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001592\n",
            "saving the model at the end of epoch 385, iters 1540\n",
            "End of epoch 385 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001493\n",
            "End of epoch 386 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001393\n",
            "End of epoch 387 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001294\n",
            "End of epoch 388 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001194\n",
            "End of epoch 389 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001095\n",
            "saving the model at the end of epoch 390, iters 1560\n",
            "End of epoch 390 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000995\n",
            "End of epoch 391 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000896\n",
            "End of epoch 392 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000796\n",
            "End of epoch 393 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000697\n",
            "End of epoch 394 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000597\n",
            "saving the model at the end of epoch 395, iters 1580\n",
            "End of epoch 395 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000498\n",
            "End of epoch 396 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000398\n",
            "End of epoch 397 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000299\n",
            "End of epoch 398 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000199\n",
            "End of epoch 399 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000100\n",
            "(epoch: 400, iters: 4, time: 0.466, data: 0.141) G_GAN: 0.312 D_real: 0.256 D_fake: 0.198 G: 3.725 NCE_A: 2.914 NCE_B: 5.511 NCE_Y: 1.814 \n",
            "saving the model at the end of epoch 400, iters 1600\n",
            "End of epoch 400 / 400 \t Time Taken: 3 sec\n",
            "learning rate = 0.0000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d86nrzqbDZTs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3894af4f-c4c4-47ba-8fc2-876b909210c4"
      },
      "source": [
        "!ls ./checkpoints/rbd2therm_CUT/"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access './checkpoints/rbd2therm_CUT/': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7I8v8p6qa8bN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "7835cf17-8620-4046-b15f-c8030ba9a58c"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('./checkpoints/rgb2therm_CUT/latest_net_F.pth')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_24c0baa0-d080-47d6-b94a-18796196c9fa\", \"latest_net_F.pth\", 2246354)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbBSlniqPEiK"
      },
      "source": [
        "##Test\n",
        "\n",
        "\n",
        "\n",
        "*   `--num_test`: how many test images to produce\n",
        "*   `--direction`: `AtoB` or `BtoA`\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vgnZhxLOEHf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b821bf1-9a7f-4cff-a5e3-940165469073"
      },
      "source": [
        "!python test.py --dataroot ./datasets/rgb2therm/ \\\n",
        " --direction AtoB \\\n",
        " --max_dataset_size 4 \\\n",
        " --name rgb2therm_CUT \\\n",
        " --load_size 286 \\\n",
        " --crop_size 256 \\\n",
        " --input_nc 1 \\\n",
        " --output_nc 1 \\\n",
        "--CUT_mode CUT"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------- Options ---------------\n",
            "                 CUT_mode: CUT                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ./datasets/rgb2therm/         \t[default: placeholder]\n",
            "             dataset_mode: unaligned                     \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "               easy_label: experiment_name               \n",
            "                    epoch: latest                        \n",
            "                     eval: False                         \n",
            "        flip_equivariance: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: xavier                        \n",
            "                 input_nc: 1                             \t[default: 3]\n",
            "                  isTrain: False                         \t[default: None]\n",
            "               lambda_GAN: 1.0                           \n",
            "               lambda_NCE: 1.0                           \n",
            "                load_size: 286                           \t[default: 256]\n",
            "         max_dataset_size: 4                             \t[default: inf]\n",
            "                    model: cut                           \n",
            "               n_layers_D: 3                             \n",
            "                     name: rgb2therm_CUT                 \t[default: experiment_name]\n",
            "                    nce_T: 0.07                          \n",
            "                  nce_idt: True                          \n",
            "nce_includes_all_negatives_from_minibatch: False                         \n",
            "               nce_layers: 0,4,8,12,16                   \n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netF: mlp_sample                    \n",
            "                  netF_nc: 256                           \n",
            "                     netG: resnet_9blocks                \n",
            "                      ngf: 64                            \n",
            "             no_antialias: False                         \n",
            "          no_antialias_up: False                         \n",
            "               no_dropout: True                          \n",
            "                  no_flip: False                         \n",
            "                    normD: instance                      \n",
            "                    normG: instance                      \n",
            "              num_patches: 256                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 1                             \t[default: 3]\n",
            "                    phase: test                          \n",
            "                pool_size: 0                             \n",
            "               preprocess: resize_and_crop               \n",
            "         random_scale_max: 3.0                           \n",
            "              results_dir: ./results/                    \n",
            "           serial_batches: False                         \n",
            "stylegan2_G_num_downsampling: 1                             \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [UnalignedDataset] was created\n",
            "dataset [UnalignedDataset] was created\n",
            "model [CUTModel] was created\n",
            "creating web directory ./results/rgb2therm_CUT/test_latest\n",
            "loading the model from ./checkpoints/rgb2therm_CUT/latest_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 11.366 M\n",
            "-----------------------------------------------\n",
            "processing (0000)-th image... ['./datasets/rgb2therm/testA/003_02_D1_vis.bmp']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r ./datasets/rgb2therm/trainB/ ./datasets/rgb2therm/testB"
      ],
      "metadata": {
        "id": "7uRdeDmP6tiH"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}